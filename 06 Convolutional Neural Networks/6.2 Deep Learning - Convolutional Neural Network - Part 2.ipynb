{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f735824",
   "metadata": {},
   "source": [
    "### The Cross-Correlation Operation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ad53138",
   "metadata": {},
   "source": [
    "![correlation.svg](../images/correlation.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd446cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.093309Z",
     "start_time": "2022-04-29T15:34:37.854694Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j].assign(tf.reduce_sum(\n",
    "                X[i: i + h, j: j + w] * K))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9197f31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.156138Z",
     "start_time": "2022-04-29T15:34:40.094952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[19., 25.],\n",
       "       [37., 43.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = tf.constant([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1dc66f",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f722993f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.172132Z",
     "start_time": "2022-04-29T15:34:40.157933Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, kernel_size):\n",
    "        initializer = tf.random_normal_initializer()\n",
    "        self.weight = self.add_weight(name='w', shape=kernel_size,\n",
    "                                      initializer=initializer)\n",
    "        self.bias = self.add_weight(name='b', shape=(1, ),\n",
    "                                    initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return corr2d(inputs, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a36a38",
   "metadata": {},
   "source": [
    "### Object Edge Detection in Images\n",
    "\n",
    "The middle four columns are black (0) and the rest are white (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398ec329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.187873Z",
     "start_time": "2022-04-29T15:34:40.174133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=\n",
       "array([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.Variable(tf.ones((6, 8)))\n",
    "X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e3435",
   "metadata": {},
   "source": [
    "#### Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4901666c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.203436Z",
     "start_time": "2022-04-29T15:34:40.189905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = tf.constant([[1.0, -1.0]])\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfde4d",
   "metadata": {},
   "source": [
    "#### We are ready to perform the cross-correlation operation with arguments X (our input) and K (our kernel). As you can see, we detect 1 for the edge from white to black and -1 for the edge from black to white. All other outputs take value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc74112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.234772Z",
     "start_time": "2022-04-29T15:34:40.205402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a199675",
   "metadata": {},
   "source": [
    "#### We can now apply the kernel to the transposed image. As expected, it vanishes. The kernel K only detects vertical edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc30631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.266108Z",
     "start_time": "2022-04-29T15:34:40.236678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(tf.transpose(X), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a02e51",
   "metadata": {},
   "source": [
    "### Learning a Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625ae71",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97143ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.282108Z",
     "start_time": "2022-04-29T15:34:40.268108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
    "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
    "conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e4301",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee521edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.344986Z",
     "start_time": "2022-04-29T15:34:40.284107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 19.268\n",
      "epoch 2, loss 9.164\n",
      "epoch 3, loss 4.568\n",
      "epoch 4, loss 2.392\n",
      "epoch 5, loss 1.313\n",
      "epoch 6, loss 0.751\n",
      "epoch 7, loss 0.444\n",
      "epoch 8, loss 0.269\n",
      "epoch 9, loss 0.166\n",
      "epoch 10, loss 0.104\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "X = tf.reshape(X, (1, 6, 8, 1))\n",
    "y = tf.reshape(Y, (1, 6, 7, 1))\n",
    "lr = 3e-2  # Learning rate\n",
    "\n",
    "y_hat = conv2d(X)\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute gradients and update parameters\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(conv2d.weights[0])\n",
    "        y_hat = conv2d(X)\n",
    "        l = (abs(y_hat - y)) ** 2\n",
    "        # Update the kernel\n",
    "        grads = tape.gradient(l, conv2d.weights[0])\n",
    "        weights = conv2d.get_weights()\n",
    "        weights[0] = conv2d.weights[0] - tf.multiply(lr, grads)\n",
    "        conv2d.set_weights(weights)\n",
    "        print(f'epoch {epoch + 1}, loss {tf.reduce_sum(l):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a110e9",
   "metadata": {},
   "source": [
    "#### Now we will take a look at the kernel tensor we learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c3299c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:34:40.360643Z",
     "start_time": "2022-04-29T15:34:40.346679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.95508915, -1.0202311 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(conv2d.get_weights()[0], (1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5010d",
   "metadata": {},
   "source": [
    "### Cross-Correlation and Convolution\n",
    "\n",
    "What we did is not strict convolution but cross-correlation. A strict convolution can be done by doing transformation on the kernel and since, the kernel is learned, so it doesn't matter if we do a strict convolution, so we're good with cross-correlation and we refer to it as convolution, even though that's not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3adb1ee",
   "metadata": {},
   "source": [
    "### Feature Map and Receptive Field\n",
    "\n",
    "The output of cross-correlation operation is called Feature map. The Feature Map becomes an input for the subsequent layers, given x as input to any subsequent layer, then Receptive Fields refer to all the elements that contribute to calculate x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46ec6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
