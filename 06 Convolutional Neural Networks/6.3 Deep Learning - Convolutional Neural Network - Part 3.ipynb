{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d9e114",
   "metadata": {},
   "source": [
    "### Padding \n",
    "\n",
    "Preserving boundary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2bfee1",
   "metadata": {},
   "source": [
    "Two-dimensional cross-correlation with padding\n",
    "\n",
    "![conv-pad](../images/conv-pad.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b9818",
   "metadata": {},
   "source": [
    "In general, if we add a total of $p_h$ rows of padding (roughly half on top and half on bottom) and a total of $p_w$ columns of padding (roughly half on the left and half on the right), the output shape will be\n",
    "$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee5cef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T14:51:54.052780Z",
     "start_time": "2022-04-30T14:51:51.625855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# We define a convenience function to calculate the convolutional layer. This\n",
    "# function initializes the convolutional layer weights and performs\n",
    "# corresponding dimensionality elevations and reductions on the input and\n",
    "# output\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # Here (1, 1) indicates that the batch size and the number of channels\n",
    "    # are both 1\n",
    "    X = tf.reshape(X, (1, ) + X.shape + (1, ))\n",
    "    Y = conv2d(X)\n",
    "    # Exclude the first two dimensions that do not interest us: examples and\n",
    "    # channels\n",
    "    return tf.reshape(Y, Y.shape[1:3])\n",
    "# Note that here 1 row or column is padded on either side, so a total of 2\n",
    "# rows or columns are added\n",
    "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same')\n",
    "X = tf.random.uniform(shape=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403186fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T14:51:54.068780Z",
     "start_time": "2022-04-30T14:51:54.055785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we use a convolution kernel with a height of 5 and a width of 3. The\n",
    "# padding numbers on either side of the height and width are 2 and 1,\n",
    "# respectively\n",
    "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='same')\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd4651",
   "metadata": {},
   "source": [
    "### Stride\n",
    "\n",
    "We refer to the number of rows and columns traversed per slide as the stride. So far, we have used strides of 1, both for height and width. Sometimes, either for computational efficiency or because we wish to downsample, we move our window more than one element at a time, skipping the intermediate locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fc69a",
   "metadata": {},
   "source": [
    "Cross-correlation with strides of 3 and 2 for height and width, respectively\n",
    "\n",
    "![conv-stride](../images/conv-stride.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c874de",
   "metadata": {},
   "source": [
    "In general, when the stride for the height is $s_h$ and the stride for the width is $s_w$, the output shape is\n",
    "\n",
    "$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3234a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T14:51:54.083780Z",
     "start_time": "2022-04-30T14:51:54.070779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855ea6df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T14:51:54.115777Z",
     "start_time": "2022-04-30T14:51:54.087780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='valid',\n",
    "                                strides=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccbfee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T14:51:54.131781Z",
     "start_time": "2022-04-30T14:51:54.118788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='same',\n",
    "                                strides=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7472e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
