{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26a1731f",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "![mlp.svg](../images/mlp.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715dcada",
   "metadata": {},
   "source": [
    "### Fashion-MNIST Data\n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9932f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T07:02:01.098770Z",
     "start_time": "2022-03-30T07:02:01.089768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels = 28 * 28\n",
    "pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8aac8",
   "metadata": {},
   "source": [
    "### Need for Convolutional neural networks (CNNs)\n",
    "For image size 1 Mega-pixel (pixels = $10^6$) with a thousand neurons in the first hidden layer, $\\textbf{weights}$ at first hidden layer are $10^6 \\times 10^3 = 10^9$. We have huge paremetes and we can adjust weights w.r.t. each pixel but we're not capturing some structures in the image.\n",
    "\n",
    "#### We can use Convolutional neural networks (CNNs) to capture some structures in the image to learn about the image.\n",
    "- Invariance: A patch in an image doesn't change how it looks w.r.t. where it's located in the image\n",
    " - Translation invariance: In the earliest layers, our network should respond similarly to the same patch\n",
    " - Locality: The earliest layers of the network should focus on local regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c2dc5",
   "metadata": {},
   "source": [
    "### Constraining the MLP\n",
    "Two-dimensional images $\\textbf{X}$ as inputs and their immediate hidden representations $\\textbf{H}$, where both $\\textbf{X}$ and $\\textbf{H}$ have the same shape, we now assume both $\\textbf{X}$ and $\\textbf{H}$ capturing some structures in the image.\n",
    "\n",
    "For $\\text{Vector:}\\textbf{X} = [x_1, x_2, x_3] = [1, 2, 3]$, we use $\\text{Matrix:}\\textbf{W}$ to represent weights. If we've to pass each feature to every weight, then we'll need to represent each weight as a Vector, thus making a $\\text{Order-3 Tensor:}\\textbf{W}$. Similarly as images are represented as $\\text{Matrix:}\\textbf{X}$, we'll need a $\\text{Order-4 Tensor:}\\textbf{W}$.\n",
    "\n",
    "$\\begin{split}\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned},\\end{split}$\n",
    "\n",
    "substituting $k = i+a$ and $l = j+b$ and $[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$\n",
    "\n",
    "For any given location $(i, j)$, $[\\mathbf{H}]_{i, j}$ is summing over pixels in $x$ centered around $(i, j)$ and weighted by $[\\mathsf{V}]_{i, j, a, b}$\n",
    "\n",
    "Translation Invariance: If $\\textbf{X}$ changes, so should $\\textbf{H}$ so $\\textbf{U}$ and $\\textbf{V}$ doesn't depend on $(i, j)$. Therefore, $[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}$. This is convolution.\n",
    "\n",
    "Locality: Focus on local regions, so outside some range $|a|> \\Delta$ or $|b| > \\Delta$, we should set, $[\\mathbf{V}]_{a, b} = 0$. Therefore, $[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}$. This is a convolutional layer.\n",
    "\n",
    "Convolutional neural networks (CNNs) are a special family of neural networks that contain convolutional layers. $\\textbf{V}$ is also known as convolution kernel or a filter.\n",
    "\n",
    "Now we only need to learn about the patches, not the whole image. Previously we needed a Billion parameters, now we only need a few hundred, without reducing the dimensionality of the Input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0215653",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "\n",
    "The convolution between two functions, say $f, g: \\mathbb{R}^d \\to \\mathbb{R}$ is defined as\n",
    "\n",
    "$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}$\n",
    "\n",
    "For discrete objects,\n",
    "\n",
    "$(f * g)(i) = \\sum_a f(a) g(i-a)$\n",
    "\n",
    "and with 2-D,\n",
    "\n",
    "$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f3a68",
   "metadata": {},
   "source": [
    "### Channels\n",
    "\n",
    "An image can have 3 channels. We thus index $\\mathsf{X}$ as $[\\mathsf{X}]_{i, j, k}$. The convolutional filter has to adapt accordingly. Instead of $[\\mathbf{V}]_{a,b}$ we now have $[\\mathsf{V}]_{a,b,c}$. \n",
    "\n",
    "To support multiple channels in both inputs ($\\mathsf{X}$) and hidden representations ($\\mathsf{H}$), we can add a fourth coordinate to $\\mathsf{V}$:$[\\mathsf{V}]_{a, b, c, d}$. Putting everything together we have: $[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c}$\n",
    "\n",
    "where $d$ indexes the output channels in the hidden representations $\\mathsf{H}$. The subsequent convolutional layer will go on to take a third-order tensor, $\\mathsf{H}$ , as the input. Above being more general, definition of a convolutional layer for multiple channels, where $\\mathsf{V}$ is a kernel or filter of the layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
