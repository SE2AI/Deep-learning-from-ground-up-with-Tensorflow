{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59ca86b",
   "metadata": {},
   "source": [
    "### Training Error and Generalization Error\n",
    "\n",
    "- Large training error means the model is underfitting the training set, it's not capturing enough signal, it has low variance. Low variance means high Bias.\n",
    "- Large testing error means the model is overfitting the training set, it's capturing more noise, it has high variance. High variance means low Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16665277",
   "metadata": {},
   "source": [
    "### Statistical Learning Theory\n",
    "\n",
    "- i.i.d. assumption - the data for both training and testing has been draw independently from indentical distributions. E.g., data from cancer patients of China, may not be the same as the cancer patients from India, even though both are for cancer patients, ones may have several features different from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a0221",
   "metadata": {},
   "source": [
    "### Model Complexity\n",
    "- With large tunable-parameters, i.e., hyperparameters - learning rate, number of neurons, etc, model could overfit\n",
    "- Training on less data could overfit the model\n",
    "- Having wider range of values for weights could overfit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb038d",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "- Validation Dataset - split training data into train and validation sets, tune the hyperparameters based on train and validation set performance. Also do a 3rd split - test data, but do not tune the model further. The performance on test split should be the performance of the model when deployed in real-world.\n",
    "\n",
    "- K-Fold Cross-Validation - When we've less data, we like to use the entire dataset. So, generate 3 sets from the entire dataset for train, validate and test. Repeat it N times and pick the best model. Finally train the model with entire dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf721f7b",
   "metadata": {},
   "source": [
    "### Combat overfit using Regularization\n",
    "- Using L2-Regularization\n",
    "    - $L(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2$, where $\\lambda$ is regularization constant\n",
    "    - Weight update: \n",
    "       $\n",
    "       \\begin{split}\\begin{aligned}\n",
    "        \\mathbf{w} & \\leftarrow \\left(1- \\eta\\lambda \\right) \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)\n",
    "        \\end{aligned}\\end{split}\n",
    "       $\n",
    "- Using Dropout Regularization\n",
    "    - Each intermediate activation $h$ is replaced by a random variable $h'$ as follows:\n",
    "       $\n",
    "       \\begin{split}\\begin{aligned}\n",
    "        h' =\n",
    "        \\begin{cases}\n",
    "            0 & \\text{ with probability } p \\\\\n",
    "            \\frac{h}{1-p} & \\text{ otherwise}\n",
    "        \\end{cases}\n",
    "        \\end{aligned}\\end{split}\n",
    "       $\n",
    "       \n",
    "       ![dropout2.svg](../images/dropout2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93b480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
