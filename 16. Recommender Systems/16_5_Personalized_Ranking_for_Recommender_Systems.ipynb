{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16.5 Personalized Ranking for Recommender Systems",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Most feedback is not explicit but implicit in real-world scenarios.\n",
        "\n",
        "- Non-observed user-item pairs which may be predictive for users' interests are totally ignored in matrix factorization and AutoRec. These models are not suitable for personalized ranking tasks.\n",
        "\n",
        "- We'll discuss models targeting at generating ranked recommendation lists from implicit feedback.\n",
        "\n",
        "- Personalized ranking models can be optimized with pointwise, pairwise or listwise approaches.\n",
        "\n",
        "- Pointwise approaches considers a single interaction at a time and train a classifier or a regressor to predict individual preferences. Matrix factorization and AutoRec are optimized with pointwise objectives.\n",
        "\n",
        "- Pairwise approaches consider a pair of items for each user and aim to approximate the optimal ordering for that pair.\n",
        "\n",
        "- Listwise approaches approximate the ordering of the entire list of items.\n",
        "\n",
        "#### In this section, we will introduce two pairwise objectives/losses"
      ],
      "metadata": {
        "id": "KPmWQfnGHg11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Personalized Ranking Loss and its Implementation\n",
        "\n",
        "In formal, the training data is constructed by tuples in the form of $(u, i, j)$, which represents that the user $u$ prefers the item $i$ over the item $j$.\n",
        "\n",
        "<img src=\"https://classic.d2l.ai/_images/rec-ranking.svg\" />\n",
        "\n",
        "$\\begin{split}\\begin{aligned}\n",
        "\\text{BPR-OPT} : &= \\sum_{(u, i, j \\in D)} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) - \\lambda_\\Theta \\|\\Theta \\|^2\n",
        "\\end{aligned}\\end{split}$"
      ],
      "metadata": {
        "id": "IhycZGb0OU5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZBWfirxFeK-"
      },
      "outputs": [],
      "source": [
        "!pip install mxnet-cu101==1.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==0.17.5"
      ],
      "metadata": {
        "id": "F8MgG29Lo4tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mxnet import gluon, np, npx\n",
        "\n",
        "npx.set_np()"
      ],
      "metadata": {
        "id": "u-ejjAMxo6U-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BPRLoss(gluon.loss.Loss):\n",
        "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
        "        super(BPRLoss, self).__init__(weight=None, batch_axis=0, **kwargs)\n",
        "\n",
        "    def forward(self, positive, negative):\n",
        "        distances = positive - negative\n",
        "        loss = - np.sum(np.log(npx.sigmoid(distances)), 0, keepdims=True)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "mTazGh6Go8i9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hinge Loss and its Implementation\n",
        "\n",
        "$\\sum_{(u, i, j \\in D)} \\max( m - \\hat{y}_{ui} + \\hat{y}_{uj}, 0)$, where $m$ is the safety margin size."
      ],
      "metadata": {
        "id": "QpXqloXXpA94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLossbRec(gluon.loss.Loss):\n",
        "    def __init__(self, weight=None, batch_axis=0, **kwargs):\n",
        "        super(HingeLossbRec, self).__init__(weight=None, batch_axis=0,\n",
        "                                            **kwargs)\n",
        "\n",
        "    def forward(self, positive, negative, margin=1):\n",
        "        distances = positive - negative\n",
        "        loss = np.sum(np.maximum(- distances + margin, 0))\n",
        "        return loss"
      ],
      "metadata": {
        "id": "fVoh3kSSo_Cl"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}