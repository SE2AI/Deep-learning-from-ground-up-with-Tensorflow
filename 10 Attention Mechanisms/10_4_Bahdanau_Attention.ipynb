{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.4. Bahdanau Attention",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Download Template"
      ],
      "metadata": {
        "id": "5oc8qgGfo4i8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4tGjLsBowaJ",
        "outputId": "f4dd6ba0-7171-4cda-a1da-9391e82885df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-24 00:06:42--  https://gist.githubusercontent.com/b1nch3f/b702d2ebfd2c751aa21b68c7425e0d4e/raw/c77225291924a8d2c33c210d74f2744210b6b716/d2l.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59707 (58K) [text/plain]\n",
            "Saving to: ‘d2l.py’\n",
            "\n",
            "\rd2l.py                0%[                    ]       0  --.-KB/s               \rd2l.py              100%[===================>]  58.31K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-07-24 00:06:42 (5.05 MB/s) - ‘d2l.py’ saved [59707/59707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://gist.githubusercontent.com/b1nch3f/b702d2ebfd2c751aa21b68c7425e0d4e/raw/c77225291924a8d2c33c210d74f2744210b6b716/d2l.py -O d2l.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "<img src=\"https://classic.d2l.ai/_images/seq2seq-attention-details.svg\" />\n",
        "\n",
        "$\\mathbf{c}_{t'} = \\sum_{t=1}^T \\alpha(\\mathbf{s}_{t' - 1}, \\mathbf{h}_t) \\mathbf{h}_t$"
      ],
      "metadata": {
        "id": "tE5zjdeCue85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import d2l"
      ],
      "metadata": {
        "id": "1HQLpIgCiPXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Decoder with Attention"
      ],
      "metadata": {
        "id": "1NLB9TBTvAYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(d2l.Decoder):\n",
        "    \"\"\"The base attention-based decoder interface.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "H-IXNKJavBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention = d2l.AdditiveAttention(num_hiddens, num_hiddens,\n",
        "                                               num_hiddens, dropout)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells(\n",
        "            [tf.keras.layers.GRUCell(num_hiddens, dropout=dropout)\n",
        "             for _ in range(num_layers)]),\n",
        "                                      return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
        "        # Shape of `outputs`: (`batch_size`, `num_steps`, `num_hiddens`).\n",
        "        # Shape of `hidden_state[0]`: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        outputs, hidden_state = enc_outputs\n",
        "        return (outputs, hidden_state, enc_valid_lens)\n",
        "\n",
        "    def call(self, X, state, **kwargs):\n",
        "        # Shape of `enc_outputs`: (`batch_size`, `num_steps`, `num_hiddens`).\n",
        "        # Shape of `hidden_state[0]`: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        enc_outputs, hidden_state, enc_valid_lens = state\n",
        "        # Shape of the output `X`: (`num_steps`, `batch_size`, `embed_size`)\n",
        "        X = self.embedding(X) # Input `X` has shape: (`batch_size`, `num_steps`)\n",
        "        X = tf.transpose(X, perm=(1, 0, 2))\n",
        "        outputs, self._attention_weights = [], []\n",
        "        for x in X:\n",
        "            # Shape of `query`: (`batch_size`, 1, `num_hiddens`)\n",
        "            query = tf.expand_dims(hidden_state[-1], axis=1)\n",
        "            # Shape of `context`: (`batch_size, 1, `num_hiddens`)\n",
        "            context = self.attention(query, enc_outputs, enc_outputs,\n",
        "                                     enc_valid_lens, **kwargs)\n",
        "            # Concatenate on the feature dimension\n",
        "            x = tf.concat((context, tf.expand_dims(x, axis=1)), axis=-1)\n",
        "            out = self.rnn(x, hidden_state, **kwargs)\n",
        "            hidden_state = out[1:]\n",
        "            outputs.append(out[0])\n",
        "            self._attention_weights.append(self.attention.attention_weights)\n",
        "        # After fully-connected layer transformation, shape of `outputs`:\n",
        "        # (`batch_size`, `num_steps`, `vocab_size`)\n",
        "        outputs = self.dense(tf.concat(outputs, axis=1))\n",
        "        return outputs, [enc_outputs, hidden_state, enc_valid_lens]\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ],
      "metadata": {
        "id": "t7TtcgVpvHSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = d2l.Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
        "                             num_layers=2)\n",
        "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
        "                                  num_layers=2)\n",
        "X = tf.zeros((4, 7))\n",
        "state = decoder.init_state(encoder(X, training=False), None)\n",
        "output, state = decoder(X, state, training=False)\n",
        "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
      ],
      "metadata": {
        "id": "cVNPxtmHvJ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "0eEkXOokvMQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
        "batch_size, num_steps = 64, 10\n",
        "lr, num_epochs, device = 0.005, 250, d2l.try_gpu()\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
        "encoder = d2l.Seq2SeqEncoder(\n",
        "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqAttentionDecoder(\n",
        "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "net = d2l.EncoderDecoder(encoder, decoder)\n",
        "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
      ],
      "metadata": {
        "id": "-uVkQQLjvM9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
        "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
        "for eng, fra in zip(engs, fras):\n",
        "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
        "        net, eng, src_vocab, tgt_vocab, num_steps, True)\n",
        "    print(f'{eng} => {translation}, ',\n",
        "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}')"
      ],
      "metadata": {
        "id": "mpBQqiQ6vPqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plus one to include the end-of-sequence token\n",
        "d2l.show_heatmaps(attention_weights[:, :, :, :len(engs[-1].split()) + 1],\n",
        "                  xlabel='Key posistions', ylabel='Query posistions')"
      ],
      "metadata": {
        "id": "XI54EykavRWY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}